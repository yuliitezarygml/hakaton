package services

import (
	"encoding/json"
	"fmt"
	"log"
	"regexp"
	"strings"
	"text-analyzer/models"
)

// AIClient â€” Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Ğ´Ğ»Ñ Ğ»ÑĞ±Ğ¾Ğ³Ğ¾ AI Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ° (OpenRouter, Groq, LMStudio)
type AIClient interface {
	Analyze(text string) (string, error)
}

type AnalyzerService struct {
	client       AIClient
	fetcher      *ContentFetcher
	serper       *SerperClient
	promptConfig *PromptConfig
}

func NewAnalyzerService(client AIClient, fetcher *ContentFetcher, serper *SerperClient, promptConfig *PromptConfig) *AnalyzerService {
	return &AnalyzerService{
		client:       client,
		fetcher:      fetcher,
		serper:       serper,
		promptConfig: promptConfig,
	}
}

// NewAnalyzerServiceGroq â€” Ğ°Ğ»Ğ¸Ğ°Ñ Ğ´Ğ»Ñ ÑƒĞ´Ğ¾Ğ±ÑÑ‚Ğ²Ğ° (Ñ‚Ğ¾Ñ‚ Ğ¶Ğµ ĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ‚Ğ¾Ñ€)
func NewAnalyzerServiceGroq(client *GroqClient, fetcher *ContentFetcher, serper *SerperClient, promptConfig *PromptConfig) *AnalyzerService {
	return NewAnalyzerService(client, fetcher, serper, promptConfig)
}

func (s *AnalyzerService) AnalyzeText(text string, progress ...func(string)) (*models.AnalysisResponse, error) {
	report := func(msg string) {
		log.Printf("[ANALYZER] %s", msg)
		if len(progress) > 0 && progress[0] != nil {
			progress[0](msg)
		}
	}
	report("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	report(fmt.Sprintf("ğŸ“ Ğ¨ĞĞ“ 1/4 â€” ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½ Ñ‚ĞµĞºÑÑ‚ (%d ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²)", len(text)))

	var searchContext string
	if s.serper != nil && s.serper.APIKey != "" {
		report("ğŸŒ Ğ¨ĞĞ“ 2/4 â€” ĞŸĞ¾Ğ¸ÑĞº Ñ„Ğ°ĞºÑ‚Ğ¾Ğ² Ğ² Google (RU + EN + RO)...")
		searchResults, err := s.serper.SearchForFactCheck(text)
		if err != nil {
			report(fmt.Sprintf("âš  ĞŸĞ¾Ğ¸ÑĞº Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½: %v", err))
		} else if searchResults != "" {
			searchContext = "\n\n--- Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯ Ğ˜Ğ— Ğ˜ĞĞ¢Ğ•Ğ ĞĞ•Ğ¢Ğ Ğ”Ğ›Ğ¯ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ˜ Ğ¤ĞĞšĞ¢ĞĞ’ ---\n" + searchResults
			report("âœ“ ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ· Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½")
		} else {
			report("âš  ĞŸĞ¾Ğ¸ÑĞº Ğ½Ğµ Ğ´Ğ°Ğ» Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²")
		}
	} else {
		report("âš  Ğ¨ĞĞ“ 2/4 â€” Serper Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°Ñ Ğ¿Ğ¾Ğ¸ÑĞº")
	}

	report("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	report(fmt.Sprintf("ğŸ¤– Ğ¨ĞĞ“ 3/4 â€” ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ Ğ² AI... (%d ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²)", len(text)+len(searchContext)))
	report("â³ ĞĞ¶Ğ¸Ğ´Ğ°Ğ¹Ñ‚Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸...")

	fullText := text + searchContext
	rawResponse, err := s.client.Analyze(fullText)
	if err != nil {
		report(fmt.Sprintf("âŒ AI Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ: %v", err))
		return nil, err
	}

	report(fmt.Sprintf("âœ“ AI Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¸Ğ» (%d ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²)", len(rawResponse)))
	report("ğŸ” Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°Ñ JSON Ğ¸Ğ· Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°...")

	jsonStr := extractJSON(rawResponse)
	jsonStr = fixJSONTypes(jsonStr)

	var response models.AnalysisResponse
	if err := json.Unmarshal([]byte(jsonStr), &response); err != nil {
		report("âš  ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ°, Ğ¿Ñ€Ğ¾Ğ±ÑƒÑ Ğ¾Ñ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ...")
		cleanJSON := strings.ReplaceAll(jsonStr, "\n", " ")
		cleanJSON = strings.ReplaceAll(cleanJSON, "\t", " ")
		if err := json.Unmarshal([]byte(cleanJSON), &response); err != nil {
			report("âŒ ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»ÑÑ â€” Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°Ñ ÑÑ‹Ñ€Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚")
			return &models.AnalysisResponse{
				Summary:     "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°Ñ€ÑĞ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚",
				RawResponse: rawResponse,
			}, nil
		}
	}

	response.RawResponse = rawResponse

	report("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	report("ğŸ“Š Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ ĞĞĞĞ›Ğ˜Ğ—Ğ:")
	report(fmt.Sprintf("   Ğ”Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ : %d/10", response.CredibilityScore))
	report(fmt.Sprintf("   ĞœĞ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¹   : %d", len(response.Manipulations)))
	report(fmt.Sprintf("   Ğ›Ğ¾Ğ³. Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº   : %d", len(response.LogicalIssues)))
	report(fmt.Sprintf("   Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²    : %d", len(response.Sources)))
	if response.CredibilityScore <= 3 {
		report("   Ğ’ĞµÑ€Ğ´Ğ¸ĞºÑ‚       : ğŸ”´ Ğ’Ğ•Ğ ĞĞ¯Ğ¢ĞĞĞ¯ Ğ”Ğ•Ğ—Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯")
	} else if response.CredibilityScore <= 6 {
		report("   Ğ’ĞµÑ€Ğ´Ğ¸ĞºÑ‚       : ğŸŸ¡ Ğ¡ĞĞœĞĞ˜Ğ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ™ ĞšĞĞĞ¢Ğ•ĞĞ¢")
	} else {
		report("   Ğ’ĞµÑ€Ğ´Ğ¸ĞºÑ‚       : ğŸŸ¢ Ğ”ĞĞ¡Ğ¢ĞĞ’Ğ•Ğ ĞĞ«Ğ™ ĞšĞĞĞ¢Ğ•ĞĞ¢")
	}
	report("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	if response.CredibilityScore <= 7 && s.serper != nil && s.serper.APIKey != "" {
		report("ğŸ” Ğ¨ĞĞ“ 4/4 â€” Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°Ñ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºÑƒÑ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ...")
		verification, err := s.verifyAndFindTruth(text, &response)
		if err != nil {
			report(fmt.Sprintf("âš  Ğ’ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ: %v", err))
		} else {
			response.Verification = *verification
			if verification.IsFake {
				report(fmt.Sprintf("ğŸš¨ Ğ˜Ğ¢ĞĞ“: Ğ¡Ğ¢ĞĞ¢Ğ¬Ğ¯ Ğ¤ĞĞ›Ğ¬Ğ¨Ğ˜Ğ’ĞĞ¯ (%d Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½)", len(verification.FakeReasons)))
			} else {
				report("âœ“ Ğ’ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°")
			}
		}
	} else {
		report(fmt.Sprintf("âœ… Ğ¨ĞĞ“ 4/4 â€” Ğ’ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ½Ğµ Ğ½ÑƒĞ¶Ğ½Ğ° (Ğ¾Ñ†ĞµĞ½ĞºĞ° %d/10)", response.CredibilityScore))
	}

	report("âœ… ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½!")
	return &response, nil
}

func (s *AnalyzerService) AnalyzeURL(url string, progress ...func(string)) (*models.AnalysisResponse, error) {
	report := func(msg string) {
		log.Printf("[ANALYZER] %s", msg)
		if len(progress) > 0 && progress[0] != nil {
			progress[0](msg)
		}
	}

	report("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	report("ğŸŒ ĞĞĞĞ›Ğ˜Ğ— Ğ¡Ğ¢ĞĞ¢Ğ¬Ğ˜ ĞŸĞ URL")
	report("   " + url)
	report("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	report("ğŸ“¥ Ğ¨Ğ°Ğ³ 1/2 â€” Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°Ñ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñƒ...")

	content, err := s.fetcher.FetchURL(url)
	if err != nil {
		report(fmt.Sprintf("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñƒ: %v", err))
		return nil, err
	}

	report(fmt.Sprintf("âœ“ Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ° (%d ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²)", len(content)))
	report("ğŸ”¬ Ğ¨Ğ°Ğ³ 2/2 â€” ĞŸĞµÑ€ĞµĞ´Ğ°Ñ Ğ½Ğ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·...")

	var progressFn func(string)
	if len(progress) > 0 {
		progressFn = progress[0]
	}
	response, err := s.AnalyzeText(content, progressFn)
	if err != nil {
		return nil, err
	}

	response.SourceURL = url
	report("ğŸ ĞĞ½Ğ°Ğ»Ğ¸Ğ· URL Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½!")
	return response, nil
}

func extractJSON(text string) string {
	// Ğ˜Ñ‰ĞµĞ¼ JSON Ğ¼ĞµĞ¶Ğ´Ñƒ ```json Ğ¸ ``` Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ { Ğ¸ }
	
	// Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ² markdown Ğ±Ğ»Ğ¾ĞºĞµ
	if strings.Contains(text, "```json") {
		start := strings.Index(text, "```json")
		if start != -1 {
			start += 7 // Ğ´Ğ»Ğ¸Ğ½Ğ° "```json"
			end := strings.Index(text[start:], "```")
			if end != -1 {
				return strings.TrimSpace(text[start : start+end])
			}
		}
	}
	
	// Ğ˜Ñ‰ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ { Ğ¸ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ }
	start := strings.Index(text, "{")
	end := strings.LastIndex(text, "}")
	
	if start != -1 && end != -1 && end > start {
		jsonStr := text[start : end+1]
		
		// ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ Ğ¾Ñ‚ escape-Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹
		jsonStr = strings.ReplaceAll(jsonStr, "\\n", " ")
		jsonStr = strings.ReplaceAll(jsonStr, "\\t", " ")
		jsonStr = strings.ReplaceAll(jsonStr, "\\\"", "\"")
		
		// ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON
		var testMap map[string]interface{}
		if err := json.Unmarshal([]byte(jsonStr), &testMap); err == nil {
			return jsonStr
		}
		
		log.Printf("[PARSER] âš  JSON Ğ½ĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°Ñ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ")
		return jsonStr
	}
	
	return text
}


// verifyAndFindTruth - Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¸ Ğ¸Ñ‰ĞµÑ‚ Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ
func (s *AnalyzerService) verifyAndFindTruth(text string, analysis *models.AnalysisResponse) (*models.Verification, error) {
	log.Printf("[VERIFIER] ğŸ” ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºÑƒÑ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ...")
	
	verification := &models.Verification{
		IsFake:      analysis.CredibilityScore <= 5,
		FakeReasons: []string{},
	}
	
	// Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹ Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ñ„Ğ°Ğ»ÑŒÑˆĞ¸Ğ²Ğ°Ñ
	if len(analysis.Manipulations) > 0 {
		verification.FakeReasons = append(verification.FakeReasons, 
			fmt.Sprintf("ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ %d Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¹ Ğ¸ Ğ¿Ñ€Ğ¸ĞµĞ¼Ğ¾Ğ² Ğ´ĞµĞ¼Ğ°Ğ³Ğ¾Ğ³Ğ¸Ğ¸", len(analysis.Manipulations)))
	}
	
	if len(analysis.LogicalIssues) > 0 {
		verification.FakeReasons = append(verification.FakeReasons,
			fmt.Sprintf("ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ %d Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ñ€ĞµÑ‡Ğ¸Ğ¹", len(analysis.LogicalIssues)))
	}
	
	if len(analysis.FactCheck.MissingEvidence) > 0 {
		verification.FakeReasons = append(verification.FakeReasons,
			fmt.Sprintf("ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ° Ğ´Ğ»Ñ %d ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¹", len(analysis.FactCheck.MissingEvidence)))
	}
	
	if len(analysis.FactCheck.OpinionsAsFacts) > 0 {
		verification.FakeReasons = append(verification.FakeReasons,
			fmt.Sprintf("ĞœĞ½ĞµĞ½Ğ¸Ñ Ğ²Ñ‹Ğ´Ğ°ÑÑ‚ÑÑ Ğ·Ğ° Ñ„Ğ°ĞºÑ‚Ñ‹: %d ÑĞ»ÑƒÑ‡Ğ°ĞµĞ²", len(analysis.FactCheck.OpinionsAsFacts)))
	}
	
	// Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸
	keywords := extractMainClaims(text, analysis)
	if len(keywords) == 0 {
		log.Printf("[VERIFIER] âš  ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ")
		return verification, nil
	}
	
	log.Printf("[VERIFIER] ğŸ”‘ ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸: %v", keywords)
	
	// Ğ˜Ñ‰ĞµĞ¼ Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğµ
	var allResults []string
	var verifiedSources []models.Source
	
	for i, claim := range keywords {
		if i >= 3 { // ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ 3 Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸
			break
		}
		
		log.Printf("[VERIFIER] ğŸŒ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑÑ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ %d: %s", i+1, claim)
		
		results, err := s.serper.SearchMultiLanguage(claim)
		if err != nil {
			log.Printf("[VERIFIER] âš  ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ¸ÑĞºĞ°: %v", err)
			continue
		}
		
		if len(results) > 0 {
			log.Printf("[VERIFIER] âœ“ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ %d Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²", len(results))
			
			// Ğ‘ĞµÑ€ĞµĞ¼ Ñ‚Ğ¾Ğ¿-3 Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°
			for j, result := range results {
				if j >= 3 {
					break
				}
				
				allResults = append(allResults, fmt.Sprintf(
					"â€¢ %s\n  Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: %s\n  %s",
					result.Title, result.Link, result.Snippet,
				))
				
				verifiedSources = append(verifiedSources, models.Source{
					Title:       result.Title,
					URL:         result.Link,
					Description: result.Snippet,
				})
			}
		}
	}
	
	if len(allResults) > 0 {
		verification.RealInformation = "ĞĞĞ¡Ğ¢ĞĞ¯Ğ©ĞĞ¯ Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯ Ğ˜Ğ— ĞŸĞ ĞĞ’Ğ•Ğ Ğ•ĞĞĞ«Ğ¥ Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞĞ’:\n\n" + 
			strings.Join(allResults, "\n\n")
		verification.VerifiedSources = verifiedSources
		
		log.Printf("[VERIFIER] âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ° Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ· %d Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²", len(verifiedSources))
	} else {
		verification.RealInformation = "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€Ğ½ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¸Ğ· ÑÑ‚Ğ°Ñ‚ÑŒĞ¸."
		log.Printf("[VERIFIER] âš  ĞĞ°ÑÑ‚Ğ¾ÑÑ‰Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°")
	}
	
	return verification, nil
}

// extractMainClaims - Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸Ğ· Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° AI (Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ Ğ½Ğ°Ğ´ ÑÑ‹Ñ€Ñ‹Ğ¼ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼)
func extractMainClaims(text string, analysis *models.AnalysisResponse) []string {
	claims := []string{}
	seen := make(map[string]bool)

	addUnique := func(s string) {
		s = strings.TrimSpace(s)
		if len(s) > 15 && len(s) < 250 && !seen[s] {
			seen[s] = true
			claims = append(claims, s)
		}
	}

	// ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ 1: Ñ„Ğ°ĞºÑ‚Ñ‹ Ğ¸Ğ· missing_evidence â€” ÑÑ‚Ğ¾ ÑĞ°Ğ¼Ñ‹Ğµ ÑĞ¾Ğ¼Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ
	for _, fact := range analysis.FactCheck.MissingEvidence {
		addUnique(fact)
		if len(claims) >= 2 {
			break
		}
	}

	// ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ 2: Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼Ñ‹Ğµ Ñ„Ğ°ĞºÑ‚Ñ‹ Ğ¸Ğ· AI-Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
	for _, fact := range analysis.FactCheck.VerifiableFacts {
		addUnique(fact)
		if len(claims) >= 4 {
			break
		}
	}

	// ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ 3: Ğ¼Ğ½ĞµĞ½Ğ¸Ñ, Ğ¿Ğ¾Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ĞºĞ°Ğº Ñ„Ğ°ĞºÑ‚Ñ‹
	for _, op := range analysis.FactCheck.OpinionsAsFacts {
		addUnique(op)
		if len(claims) >= 5 {
			break
		}
	}

	// Fallback: ĞµÑĞ»Ğ¸ AI Ğ½Ğµ Ğ´Ğ°Ğ» Ñ„Ğ°ĞºÑ‚Ğ¾Ğ², Ğ¸Ñ‰ĞµĞ¼ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ñ Ñ‡Ğ¸ÑĞ»Ğ°Ğ¼Ğ¸/Ğ¸Ğ¼ĞµĞ½Ğ°Ğ¼Ğ¸ Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ
	if len(claims) == 0 {
		reNumbers := regexp.MustCompile(`\d`)
		sentences := strings.Split(text, ".")
		for _, sentence := range sentences {
			sentence = strings.TrimSpace(sentence)
			// ĞŸÑ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ñ Ñ†Ğ¸Ñ„Ñ€Ğ°Ğ¼Ğ¸ Ğ¸Ğ»Ğ¸ Ğ·Ğ°Ğ³Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¼Ğ¸ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼Ğ¸ (Ğ¸Ğ¼ĞµĞ½Ğ°, Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸)
			if len(sentence) > 30 && len(sentence) < 200 && reNumbers.MatchString(sentence) {
				addUnique(sentence)
				if len(claims) >= 3 {
					break
				}
			}
		}
		// Ğ•ÑĞ»Ğ¸ Ñ Ñ†Ğ¸Ñ„Ñ€Ğ°Ğ¼Ğ¸ Ğ½Ğµ Ğ½Ğ°ÑˆĞ»Ğ¸ â€” Ğ±ĞµÑ€Ñ‘Ğ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
		if len(claims) == 0 {
			for _, sentence := range sentences {
				sentence = strings.TrimSpace(sentence)
				if len(sentence) > 30 && len(sentence) < 200 {
					addUnique(sentence)
					if len(claims) >= 3 {
						break
					}
				}
			}
		}
	}

	return claims
}


// fixJSONTypes Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ‚Ğ¸Ğ¿Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² JSON (ÑÑ‚Ñ€Ğ¾ĞºĞ¸ -> Ñ‡Ğ¸ÑĞ»Ğ°/bool)
func fixJSONTypes(jsonStr string) string {
	// Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ credibility_score: "1" -> 1 Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ±ĞµĞ· ĞºĞ°Ğ²Ñ‹Ñ‡ĞµĞº
	re := regexp.MustCompile(`"credibility_score"\s*:\s*"?(\d+)"?`)
	jsonStr = re.ReplaceAllString(jsonStr, `"credibility_score": $1`)
	
	// Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ is_fake: "true" -> true, "false" -> false
	jsonStr = strings.ReplaceAll(jsonStr, `"is_fake": "true"`, `"is_fake": true`)
	jsonStr = strings.ReplaceAll(jsonStr, `"is_fake": "false"`, `"is_fake": false`)
	jsonStr = strings.ReplaceAll(jsonStr, `"is_fake": true`, `"is_fake": true`) // ÑƒĞ¶Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾
	jsonStr = strings.ReplaceAll(jsonStr, `"is_fake": false`, `"is_fake": false`) // ÑƒĞ¶Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾
	
	return jsonStr
}
